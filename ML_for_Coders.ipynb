{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOslcOcNcxBghgqydOZ+tkY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattcturek/ML-For-Coders/blob/main/ML_for_Coders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 1\n",
        "\n",
        "### Single Nuron Neural Network as a \"Hello World!\" application."
      ],
      "metadata": {
        "id": "9rma4l26osKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify the TensorFlow Version"
      ],
      "metadata": {
        "id": "1AEC5akHo1Z4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Rq-s_k2nudQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf;\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a Neural Netowrk using TensorFlow and Keras APIs"
      ],
      "metadata": {
        "id": "gSr-EFR7o937"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.engine.training import optimizer\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([Dense(units=1, input_shape=[1])])\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
        "\n",
        "model.fit(xs, ys, epochs=500)\n",
        "\n",
        "print(model.predict([10.0]))"
      ],
      "metadata": {
        "id": "TGnUTIIWpLim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same code with it showing the weights and loss."
      ],
      "metadata": {
        "id": "5RV3xq1GrGdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.utils.data_utils import SequenceEnqueuer\n",
        "from keras.src.engine.training import optimizer\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "l0 = Dense(units=1, input_shape=[1])\n",
        "model = Sequential([l0])\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
        "\n",
        "model.fit(xs, ys, epochs=500)\n",
        "\n",
        "print(model.predict([10.0]))\n",
        "print(\"Here is what I learned: {}\".format(l0.get_weights()))"
      ],
      "metadata": {
        "id": "q7tbj3cMrOkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running this code, it will you what it thinks the X is, and then what it thinks the relationship of Y to X."
      ],
      "metadata": {
        "id": "vUM34tZWvpwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 2\n",
        "### Computer Vision"
      ],
      "metadata": {
        "id": "HyLPnEWXwQh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we will make a neural network that will look at an image of a piece of clothing, then categorize it and try to guess the correct category."
      ],
      "metadata": {
        "id": "SfSAc_v3wcnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Neurons for Vision\n",
        "\n",
        "In Chapter 1, you saw a very simple secenario where a machine was given a set of X and Y values, and it learned that the relationship between was Y=2X-1. This was done using a very simple neural network with one layer and one neuron.  \n",
        "\n",
        "In this example we are uisng Fashion-MNIST dataset that comes with Keras. It is a set of images of clothing to train the model on. Each of our images is a set of 784 values (28 x 28) between 0 and 255. They can be our X.\n",
        "\n",
        "We know that we have 10 different types of images in our dataset, so let's consider them to be our Y. Now we want to learn what the function looks like where Y is a function of X.\n",
        "\n",
        "Below is the code for the model including the dataset."
      ],
      "metadata": {
        "id": "B0cyAH7Fx5A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "data = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = data.load_data()\n",
        "\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=25)\n",
        "#model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[9])\n",
        "print(test_labels[9])"
      ],
      "metadata": {
        "id": "e9SD6iMfzDk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can pick and choose which image in the test-images array to run through the neural network by using the\n",
        "\n",
        "```\n",
        "classifications = model.predict(test_images)  - loads the test images into the model.predict function\n",
        "print(classifications['array-number']) - prints the softmax 10 neuron weights\n",
        "print(test_label['matching-array-nunber']) - actual classification number\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "rsr9LTK6_asg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "code.\n",
        "\n",
        "The number in both array values must be the same to choose the same test image vs the same fashion category (0-9)."
      ],
      "metadata": {
        "id": "Jt5q85XVAfqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifications = model.predict(test_images)\n",
        "print(classifications[5])\n",
        "print(test_labels[5])"
      ],
      "metadata": {
        "id": "OHpM6NJEAG0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Play with the values of the classifications array and the test_labels array to discover different chances the neural network had a chance to guess the clothing type. You can see the weights of all 10 final neurons and then the actual type number (0-9).\n",
        "\n",
        "You can see how accurate it is based off the number of times you train the network in the section above."
      ],
      "metadata": {
        "id": "szJ2RYYuBOMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stopping Trianing Automatically\n",
        "\n",
        "In each of the cases so far, we've hardcoded the number of epochs we're training for. White that works, we might want to train until we reach the desired accuracy instead of constactly trying differentt numbers of epochs and training and retraining until we get to our desired value. So, for example, if we want to train until the model is at 95% accuracy on the training set, without knowing how many epochs that will take, how could we do that?\n",
        "\n",
        "The easiest approach is to use a <i>callback</i> on the training. Let's take a look at the updated code that uses callbacks:"
      ],
      "metadata": {
        "id": "eLMs8VUmGsYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.95):\n",
        "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=50, callbacks=[callbacks])"
      ],
      "metadata": {
        "id": "Rbx_ROIiHSqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we created a new class called 'myCallBack'. This takes a <b>tf.keras.callbacks.Callback</b> as a parameter. Ini t, we define the on_epoch_end function, which will give us details about hte logs for this epoch. In these logs is an accuracy value, so all we have to do is see if it is greater than 0.95 (or 95%); if it is, we can stop training by saying <code>self.model.stop_training = True</code>\n",
        "\n",
        "Now check out the <code>model.fit</code> statement. You'll see that I've updated it to trian for 50 epochs, and then added a callbacks parameter. To this, I pass the <code>callbacks</code> object.\n",
        "\n",
        "When training, at the end of every epoch, the callback function will be called. So at the end of each epoch you'll check, and after about 34 epochs you'll see that your training will end, becuase the training has hit 95% accuracy (your number may be slightly different becaues of the initial random initialization, but it will likely be quite close to 34)"
      ],
      "metadata": {
        "id": "oghTiSruIvhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3\n",
        "### Dectecting Features in Images"
      ],
      "metadata": {
        "id": "uQR_Qf79SUbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutions"
      ],
      "metadata": {
        "id": "QptSYPZkR9xh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A convolution is simply a filter of weights that are used to multiply a pixel with its neighbors to get a new value for hte pixel.\n",
        "\n",
        "In our example we are going to use the Fashion MNIST Data Set, yet we are going to create a filter that is 3x3 to cover each pixel in the image. We then multiply the pixel color (greyscale) by the filter numbers, then summed up to change the number representing that pixel. Then the filter is moved to the next pixel and the story repeats."
      ],
      "metadata": {
        "id": "IG7oIExfSniN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pooling"
      ],
      "metadata": {
        "id": "o3khqueOXTal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pooling is the process of eliminating piels in your image while maintaining teh semantics of the content within the image. It's best explained visually.\n",
        "\n",
        "Here is an example of <i>max</i> pooling."
      ],
      "metadata": {
        "id": "Ru63hLRkXY0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a 4x4 image containing 16 pixels. Each group of 2x2 pixels in the upper left corner, upper right corner, lower left corner, and lower right corner. Each is 2x2. The highest number of each 2x2 array from the original image is processed and then sent to a 2x2 (4 pixel) array."
      ],
      "metadata": {
        "id": "ggyscCTrXqK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing Convultional Neural Networks"
      ],
      "metadata": {
        "id": "5zpGxxAkYO2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the code from the original neural network that processed the same data. Now we are going to add convolutional layers and pooling layers to the neural network and check performance\n",
        "\n",
        "<code>\n",
        "import tensorflow as tf<br>\n",
        "data = tf.keras.datasets.fashion_mnist<br><br>\n",
        "(training _images, training_labels), (test_images, test_labels) = data.load_data()<br><br>\n",
        "training_images = training_imagse / 255.0<br>\n",
        "test_images = test_images / 255.0<br><br>\n",
        "model = tf.keras.models.Sequential([<br>\n",
        "tf.keras.layers.Flatten(input_shape=(28,28)),<br>\n",
        "tf.keras.layers.Dense(128, activation=tf.nn.relu),<br>\n",
        "tf.keras.layers.Densse(10, activation=tf.nn.softmax)<br>\n",
        "])<br><br>\n",
        "model.compile(optimizer='adam', loss='sparese_categorical_crossentropy', metrics=['accuracy'])<br><br>\n",
        "model.fit(training_images, training_labes, epochs=5)\n",
        "</code>\n",
        "<br>\n",
        "<br>\n",
        "To implement a convolutional layer, you'll use the <code>tf.keras.layers.Conv2D</code> type.\n",
        "\n",
        "For example, here's a convolutional layer used as the input layer to a neural network:\n",
        "<br>\n",
        "<code>\n",
        "tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "</code>\n",
        "\n",
        "In this case we want the layer to learn 64 convolutions. It will randomly initialize these, and over time will learn the filter values that work best wo match the input values to their labels. The (3, 3) indicates the size of the filter."
      ],
      "metadata": {
        "id": "d-rif3x7YUhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how to use a pooling layer in the neural network. YOu'll typically do this immediately after the convolutional layer:\n",
        "<code>tf.keras.layers.MaxPooling2D(2, 2)</code><br>\n",
        "\n",
        "In this example we split the image into 2x2 pools and picked the maximum value in each. This operation could have been parameterized to define the pool size. those are the parameters that you can see here - the (2 x 2) indicates that our pools are 2 x 2."
      ],
      "metadata": {
        "id": "uA_a5qvUbJM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code for Convolutional Neural Network"
      ],
      "metadata": {
        "id": "QgqyW_Bsbz-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "data = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = data.load_data()\n",
        "\n",
        "training_images = training_images.reshape(60000, 28, 28, 1)\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "id": "s_JIoThUb7qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Convolutional Neural Network to Distinguish Between Horses and Humans"
      ],
      "metadata": {
        "id": "1mPDOcuxu3mC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we'll explore a more complex scenario than the Fashion MNIST classifier. We'll extend what we've learned about convolutions and convolutional neural networks to try to classify the contents of images where the location of a feature issnt' always in the sae place. I've created the Horses aor Humans dataset for this purpsose"
      ],
      "metadata": {
        "id": "Hq-xQInmvDOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Horses Or Humans Dataset\n",
        "\n",
        "The dataset for this section (https://oreil.ly/E5kbc) contains over a thousand 300 x 300 pixel images, approximately half each of horses and humans, rendered in different poses. This link takes you to download the Learning Set of images."
      ],
      "metadata": {
        "id": "zTee33GcvTIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Keras ImageDataGenerator\n",
        "\n",
        "The Fashion MNIST dataset that you've been using up to this point comes with labels. Every timage file has an associated file with the label details. Many image-based datasets do not have this, and Horses or Humans is no exception.\n",
        "\n",
        "Instea of labels, the images are sorted into subdirectories of each type. With Keras and Tensorflow, a tool called the <code>ImageDataGenerator</code> can use this structure to <i>automatically</i> assign labels to images."
      ],
      "metadata": {
        "id": "NwvEwCvQinAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the code to get the training data and extract it into the appropriately named subdirectories.\n",
        "\n",
        "This works if you don't have the dataset to upload to the venv."
      ],
      "metadata": {
        "id": "IJBwfDoxeVLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "url = 'horse-or-human\\training'\n",
        "\n",
        "file_name = \"horse-or-human.zip\"\n",
        "training_dir = 'horse-or-human/training/'\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(file_name, 'r')\n",
        "zip_ref.extractall(training_dir)\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "2G1iYOC4jg9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are not using this code to donwload and automatically unzip the file, then you will need to add this code to create the 'training_dir' folder:\n",
        "\n",
        "<code>training_dir = 'horse-or-human/training/'</code>"
      ],
      "metadata": {
        "id": "Xiz55mZknR58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the <code>ImageDataGenerator</code> we now simply use the follwoing code:"
      ],
      "metadata": {
        "id": "87UNQupsnpZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set the training_dir\n",
        "training_dir = 'horse-or-human/training'\n",
        "\n",
        "# All images will be rescaled by 1/255ths\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    training_dir,\n",
        "    target_size = (300, 300),\n",
        "    class_mode = 'binary'\n",
        ")"
      ],
      "metadata": {
        "id": "J1Ooy-j1nwj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca1c732-9160-48d8-ddce-743c6559f9c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first create an instance of the <code>ImageDataGenerator</code> called <code>train_datagen</code>. We then specify that this will generate images for the training process by flowing them from a directory. The directory is <i>training_dir</i>, as specififed earlier. We also indicate some hyperparameters about the data, such as the target size - in this case the images are 300 x 300, and the class modei s <code>binary</code>. The mode is usually <code>binary</code> if there are just two types of images (as in this case) or <code>categorical</code> if there are more than two."
      ],
      "metadata": {
        "id": "5ko4f3sqovML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutional Neural Network Architecture"
      ],
      "metadata": {
        "id": "d_Upoyg1wNAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are major differences between this dataset and the Fashion MNIST one that you have to take into account when designing an achitecture for classifying the images. First, the images are musch larger - 300 x 300 pixels - so mroe layers  may be needed.\n",
        "\n",
        "Second, the images are full color, not greyscale, so each image will have 3 channels instead of just 1.\n",
        "\n",
        "Third, there are only two image types, so we have a binary classifier that can be implemented using just a single output neuron, where it approaches 0 for one class and 1 for another. Keep these considerations in mind when exploring this architecture:"
      ],
      "metadata": {
        "id": "rAKSbAsRwWRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "WjdbODP0w6WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model with Binary Crossentropy loss factor, Root Mean Square Propagation as the optimizer, checking the 'accuracy' metric."
      ],
      "metadata": {
        "id": "c0oPWKXhyfom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "v9IwLcnMyxJh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we will use a <b>fit_generator</b> and pass it the <code>training_generator</code> we created earlier:"
      ],
      "metadata": {
        "id": "WfVsdXmqy-Rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(train_generator, epochs = 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqxuJ-BTzMRl",
        "outputId": "2caf7089-61cc-4e74-c401-8b7c2d6b8a1a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-373f6d72c78f>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator, epochs = 15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "33/33 [==============================] - 104s 3s/step - loss: -79296016.0000 - accuracy: 0.4869\n",
            "Epoch 2/15\n",
            "33/33 [==============================] - 98s 3s/step - loss: -6748932096.0000 - accuracy: 0.4869\n",
            "Epoch 3/15\n",
            "33/33 [==============================] - 95s 3s/step - loss: -80535281664.0000 - accuracy: 0.4869\n",
            "Epoch 4/15\n",
            "33/33 [==============================] - 95s 3s/step - loss: -442142916608.0000 - accuracy: 0.4869\n",
            "Epoch 5/15\n",
            "33/33 [==============================] - 96s 3s/step - loss: -1629855154176.0000 - accuracy: 0.4869\n",
            "Epoch 6/15\n",
            "33/33 [==============================] - 97s 3s/step - loss: -4800283410432.0000 - accuracy: 0.4869\n",
            "Epoch 7/15\n",
            "33/33 [==============================] - 95s 3s/step - loss: -11837572644864.0000 - accuracy: 0.4869\n",
            "Epoch 8/15\n",
            "33/33 [==============================] - 96s 3s/step - loss: -25811260276736.0000 - accuracy: 0.4869\n",
            "Epoch 9/15\n",
            "33/33 [==============================] - 95s 3s/step - loss: -51870835933184.0000 - accuracy: 0.4869\n",
            "Epoch 10/15\n",
            "33/33 [==============================] - 97s 3s/step - loss: -96868516233216.0000 - accuracy: 0.4869\n",
            "Epoch 11/15\n",
            "33/33 [==============================] - 97s 3s/step - loss: -173631938232320.0000 - accuracy: 0.4869\n",
            "Epoch 12/15\n",
            "33/33 [==============================] - 95s 3s/step - loss: -294958825209856.0000 - accuracy: 0.4869\n",
            "Epoch 13/15\n",
            "33/33 [==============================] - 96s 3s/step - loss: -480263779909632.0000 - accuracy: 0.4869\n",
            "Epoch 14/15\n",
            "33/33 [==============================] - 94s 3s/step - loss: -749605541117952.0000 - accuracy: 0.4869\n",
            "Epoch 15/15\n",
            "33/33 [==============================] - 94s 3s/step - loss: -1147299715612672.0000 - accuracy: 0.4869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run all the code in order but the beginning block where you download the images in a zip file. Then you can train the model, or you can copy and paste all the code into one code block to run."
      ],
      "metadata": {
        "id": "fppJBxaJzVE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Validation to the Horses or Humans Dataset"
      ],
      "metadata": {
        "id": "wDp_tlDYzh_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To add validation, you'll need a validation dataset that's separate from the training one. In some cases you'll get a master dataset that you have to split yourself, but in the case of Horses or Humans, there's a separate validation set that you can download."
      ],
      "metadata": {
        "id": "OMxzHZ5hznK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix A"
      ],
      "metadata": {
        "id": "6TOhaourRZVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Snippets"
      ],
      "metadata": {
        "id": "QQusU0qeO0e-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a Model:<br>\n",
        "<code>model.fit(training_data, training_answers, epochs)</code>"
      ],
      "metadata": {
        "id": "fEabKy4ZPTPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Model on New Data:<br>\n",
        "<code>model.evaluate(test_images, test_labels)</code>"
      ],
      "metadata": {
        "id": "LpKJOvSHQDEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viewing one item in the array at a time and viewing the model's result vs the actual result:<br>\n",
        "<code>\n",
        "classifications = model.predict(test_images)<br>\n",
        "print(classifications[9])<br>\n",
        "print(test_labels[9])\n",
        "</code>"
      ],
      "metadata": {
        "id": "tSuqi2jhQQ67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean Up to terminate the Kernal and free up the used memory\n",
        "\n",
        "<code>[ ] import os, signal<br>\n",
        "os.kill(os.getpid(), signal.SIGKILL)\n",
        "</code>"
      ],
      "metadata": {
        "id": "RfcqfuPJnAuD"
      }
    }
  ]
}